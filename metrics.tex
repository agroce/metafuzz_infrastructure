%\anh{Proposals must define metrics relevant to the proposal goals and address measurement and evaluation of the infrastructure. 
%Possible metrics to consider include infrastructure utilization, usability of infrastructure by researchers, diversity of users, 
%and publications that report experiments done on the infrastructure (especially by researchers other than the PIs).}

As we will be managing and releasing software via an open repository, 
natural user-facing metrics to evaluate community buy-in and uptake include the number of forks, downloads, contributors, pull requests, questions, 
stars, and feature requests. 
We will keep track of the provenance of our user base. While this project is targeted towards supporting the research community, 
we anticipate active interest and participation from industry. 
Infrastructure-specific metrics will incorporate the number, size, and diversity of fuzzers and benchmarks supported by our framework over time.

When possible, we will keep track of the numbers and types of bugs uncovered using our software stack.
We will also keep track of the number of citations and experiments enabled by our infrastructure, as well 
as other indicators of interests such as social media mentions and blog posts.

Lastly, we plan to keep track of the number of valid, tested configurations.  If our infrastructure truly supports a 
mix-and-match approach to selecting and deploying meta-fuzzing configurations, the number of supported configurations 
should grow exponentially every time a new configuration parameter is added.  If instead, we have a limited set of fixed
fuzzing configurations, this metric would grow linearly.  This metric should allow us to verify whether we are succeeding at a truly
flexible infrastructure.
